{"cells":[{"cell_type":"code","execution_count":1,"id":"76f4ad8f","metadata":{"cellView":"form","executionInfo":{"elapsed":15035,"status":"ok","timestamp":1645696834895,"user":{"displayName":"Manuel Moras","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKeuHgIh6jDz6fBvq3jb3xXulc-wmhnQ_DEmo0GQ=s64","userId":"07679852182853409026"},"user_tz":-60},"id":"76f4ad8f"},"outputs":[],"source":["#@title CÃ³digo Sequencer\n","#######################################################################################################################\n","####################################################### IMPORTS #######################################################\n","#######################################################################################################################\n","\n","import os\n","import shutil\n","import pickle\n","\n","import numpy\n","import time\n","import networkx as nx\n","from scipy.sparse import csr_matrix\n","from scipy.sparse.csgraph import minimum_spanning_tree\n","from scipy.stats import wasserstein_distance\n","from scipy.stats import energy_distance\n","from scipy.stats import entropy\n","from scipy.interpolate import interp1d\n","from joblib import Parallel, delayed, dump, load\n","import multiprocessing\n","\n","#from sequencer.distance_metrics import return_emd_mat_brute_force, return_energy_mat, return_kl_mat, return_L2_mat\n","\n","#######################################################################################################################\n","##  Sequencer Class                                                                                                  ##\n","#######################################################################################################################\n","\n","class Sequencer(object):\n","    \"\"\"An algorithm that detects one-dimensional trends (sequences) in complex datasets. To do so, To do so, it \n","    reorders objects within a set to produce the most elongated manifold describing their similarities which are \n","    measured in a multi-scale manner and using a collection of metrics. \n","\n","    Parameters\n","    ----------\n","    :param grid: numpy.ndarray(), the x-axis of the objects in the sample. The grid should consist of float values\n","                 and should not contain nan or infinite values. Since the data is assumed to be either 1D (vectors) \n","                 or 2D (matrices), the grid is assumed to be 1D or 2D as well.\n","\n","    :param objects_list: numpy.ndarray(), the list of the objects to sequence. The objects are\n","                         assumed to be interpolated to a common grid and should not contain nan of infinite values.\n","                         The data is assumed to be 1 or 2 dimensional, therefore the objects list should have 2 or \n","                         3 dimensions.\n","\n","    :param estimator_list: list of strings (default=['EMD', 'energy', 'KL', 'L2']) , a list of estimators to be used f\n","                           or the distance assignment. The current available estimators are: 'EMD', 'energy', 'KL', and 'L2'. \n","\n","    :param scale_list: list of integers or None (default=None). A list of the scales to use for each estimator. The \n","                       length of the list is similar to the number of estimators given in the input. The scales must \n","                       be interger values that correspond to the number of parts the data is divided to. If the data \n","                       is one-dimensional, a single chunk value is given for each scale, e.g., scale_list=[[1,2,4], [1,2,4]] \n","                       if estimator_list=['EMD', 'KL']. This means that the sequencer will divide each \n","                       object into 1 parts (full object), 2 parts (splitting each object into 2 parts), and 4 parts.\n","                       If the data is two-dimensional, two chunk values are given of each scale, the first describes\n","                       the horizontal direction and the seconds describes the vertical direction. For example, we will\n","                       set: scale_list= [[(1,1), (1,2), (2,1)], [(1,1), (1,2), (2,1)]] if \n","                       estimator_list=['EMD', 'KL']. The scales can be different for different estimators.\n","\n","                       if scale_list=None, then default list of scales is calculated using different powers of 2, such\n","                       that the minimal length of a part is 20 pixels. For example, if the length of the objects is 100,\n","                       then the default scales will be: 1, 2, 4. If the length of the objects is 1000, then the default\n","                       scales will be: 1, 2, 4, 8, 16, 32. For 2D objects, the set of default scales is [1, 1].\n","    \"\"\"\n","    def __init__(self, grid, objects_list, estimator_list, scale_list=None):\n","        assert ((len(grid.shape) == 1) or (len(grid.shape) == 2)), \"objects can be one- or two-dimensional\"\n","        assert (~numpy.isnan(grid)).all(), \"grid cannot contain nan values\"\n","        assert (~numpy.isinf(grid)).all(), \"grid cannot contain infinite values\"\n","        assert (~numpy.isneginf(grid)).all(), \"grid cannot contain negative infinite values\"\n","        assert ((len(objects_list.shape) == 2) or (len(objects_list.shape) == 3)), \"objects can be one- or two-dimensional\"\n","        assert (~numpy.isnan(objects_list)).all(), \"objects_list cannot contain nan values\"\n","        assert (~numpy.isinf(objects_list)).all(), \"objects_list cannot contain infinite values\"\n","        assert (~numpy.isneginf(objects_list)).all(), \"objects_list cannot contain negative infinite values\"\n","        if len(grid.shape) == 1:\n","            assert (grid.shape[0] == objects_list.shape[1]), \"the grid and the objects must have the same dimensions\"\n","        if len(grid.shape) == 2:\n","            assert ((grid.shape[0] == objects_list.shape[1]) and (grid.shape[1] == objects_list.shape[2])), \"the grid and the objects must have the same dimensions\"\n","\n","        if scale_list != None:\n","            assert numpy.fromiter([(isinstance(scale_value, int) or type(scale_value) == numpy.int64) for scale_value in numpy.array(scale_list).flatten()], dtype=bool).all(), \"scale values must all be integers\"\n","        assert numpy.fromiter([estimator_value in ['EMD', 'energy', 'KL', 'L2'] for estimator_value in estimator_list], dtype=bool).all(), \"estimators must be EMD, energy, KL or L2\"\n","        if scale_list != None:\n","            assert len(scale_list) == len(estimator_list), \"the length of scale_list must equal to the length of estimator_list\"\n","            for scale_value in scale_list:\n","                scale_shape = numpy.array(scale_value).shape\n","                assert len(grid.shape) == len(scale_shape), \"the shape of scales must be similar to the shape of the data\"\n","                if len(grid.shape) == 1:\n","                    assert scale_shape[0] < grid.shape[0], \"the scale must be smaller than the input data\"\n","                if len(grid.shape) == 2:\n","                    assert (scale_shape[0] < grid.shape[0]) and (scale_shape[1] < grid.shape[1]), \"the scale must be smaller than the input data\"\n","\n","        self.grid = grid\n","        self.objects_list = objects_list\n","        self.estimator_list = estimator_list\n","        if scale_list != None:\n","            self.scale_list = scale_list\n","        else:\n","            if len(grid.shape) == 1:\n","                length_of_object = len(objects_list[0])\n","                if length_of_object > 20:\n","                    maximal_scale_size = length_of_object / 20.\n","                    scale_list_for_estimator = list((2**numpy.arange(0, numpy.log2(maximal_scale_size))).astype(numpy.int))\n","                else:\n","                    scale_list_for_estimator = [1]\n","                scale_list = [scale_list_for_estimator] * len(self.estimator_list)\n","                self.scale_list = scale_list\n","\n","            else: # len(grid.shape) == 2:\n","                scale_list_for_estimator = [(1,1)]\n","                scale_list = [scale_list_for_estimator] * len(self.estimator_list)\n","                self.scale_list = scale_list\n","\n","        # set to None the parameters that are calculated during the execute function\n","        self.weighted_elongation_and_sequence_dictionary = None\n","        self.final_mst_elongation = None\n","        self.final_mst = None\n","        self.final_sequence = None\n","\n","\n","    def execute(self, outpath, to_print_progress=True, to_calculate_distance_matrices=True, to_save_distance_matrices=True, \\\n","        distance_matrices_inpath=None, to_save_elongations=True, to_average_N_best_estimators=False, number_of_best_estimators=None, \\\n","        to_use_parallelization=False):\n","        \"\"\"Main function of the sequencer that applies the algorithm to the data, and returns the best sequence and its elongation.\n","        (*) The function can save many intermediate products, such as the distance matrices for each estimator and scale. The user is \n","        encoraged to save these products, since they can be used later to reduce dramatically the computation time. \n","        (*) The function also allows the user to perform the majority vote using the N best estimators, instead of using all of \n","        them.\n","\n","        Parameters\n","        ----------\n","        :param outpath: string, the path of a directory to which the function will save intermediate products and the log file.\n","\n","        :param to_print_progress: boolean (default=True), whether to print the progress of the code. \n","\n","        :param to_calculate_distance_matrices: boolean (default=True), whether to calculate the distance matrices per estimator\n","            and scale. If True, the distance matrices per estimator and scale are eatimated. If the distance matrices were already\n","            calculated in a previous run of the function, the user is encoraged to set to_calculate_distance_matrices=False and \n","            provide a path where the matrices are available using distance_matrices_inpath.\n","\n","        :param to_save_distance_matrices: boolean (default=True), whether to save the estimated distance matrices or not. The user \n","            strongly encoraged to save the matrices in order to reduce the computation time of future runs.\n","\n","        :param distance_matrices_inpath: string (default=None), the input path of the distance matrices. If the distance matrices\n","            were already estimated in a previous run of the function, the user can avoid the re-computation of the distance matrices\n","            and load them from the given path. This can be done by setting to_calculate_distance_matrices=False and providing the \n","            input path of the distance matrices.\n","\n","        :param to_save_elongations: boolean (default=True), whether to save the derived elongations for each estimator and scale. \n","            For each scale, the function will also save the derived elongations of each part (chunk) into which the objects are \n","            split into. These values can be useful to map the important metrics and scales of the problem.\n","\n","        :param to_average_N_best_estimators: boolean (default=False), whether to consider only N best metrics + scales when \n","            constructing the final sequence. If to_average_N_best_estimators=True, the function will perform a majority vote\n","            only considering the N estimators (metrics + scales) with the highest elongations.\n","\n","        :param number_of_best_estimators: integer (default=None), the number of estimators to consider in the majority vote. \n","            If to_average_N_best_estimators=True, then the user must provide an integer number. \n","\n","        :param to_use_parallelization: boolean (default=False), whether to use parallelization when estimating the distance matrices. The parallelization\n","\n","        Returns\n","        -------\n","        :param final_mst_elongation: float, the final elongation of the detected sequence. \n","            This is obtained after populating the separate sequences for the different metrics+scales, averaged according to \n","            their respective elongations. See the paper for additional details.\n","        :param final_sequence: numpy.ndarray of integers, the final detected sequence. \n","        \"\"\"\n","        N_obj = len(self.objects_list)\n","        type(self.scale_list)\n","        assert ((len(self.grid.shape) == 1) or (len(self.grid.shape) == 2)), \"objects can be one- or two-dimensional\"\n","        assert (~numpy.isnan(self.grid)).all(), \"grid cannot contain nan values\"\n","        assert (~numpy.isinf(self.grid)).all(), \"grid cannot contain infinite values\"\n","        assert (~numpy.isneginf(self.grid)).all(), \"grid cannot contain negative infinite values\"\n","        assert ((len(self.objects_list.shape) == 2) or (len(self.objects_list.shape) == 3)), \"objects can be one- or two-dimensional\"\n","        assert (~numpy.isnan(self.objects_list)).all(), \"objects_list cannot contain nan values\"\n","        assert (~numpy.isinf(self.objects_list)).all(), \"objects_list cannot contain infinite values\"\n","        assert (~numpy.isneginf(self.objects_list)).all(), \"objects_list cannot contain negative infinite values\"\n","        if len(self.grid.shape) == 1:\n","            assert (self.grid.shape[0] == self.objects_list.shape[1]), \"the grid and the objects must have the same dimensions\"\n","        if len(self.grid.shape) == 2:\n","            assert ((self.grid.shape[0] == self.objects_list.shape[1]) and (self.grid.shape[1] == self.objects_list.shape[2])), \"the grid and the objects must have the same dimensions\"\n","\n","        assert numpy.fromiter([(isinstance(scale_value, int) or type(scale_value) == numpy.int64) for scale_value in numpy.array(self.scale_list).flatten()], dtype=bool).all(), \"scale values must all be integers\"\n","        assert numpy.fromiter([estimator_value in ['EMD', 'energy', 'KL', 'L2'] for estimator_value in self.estimator_list], dtype=bool).all(), \"estimators must be EMD, energy, KL or L2\"\n","        if len(self.grid.shape) == 2:\n","            assert ('EMD' not in self.estimator_list), \"EMD cannot be applied to two-dimensional objects\"\n","            assert ('energy' not in self.estimator_list), \"Energy distance cannot be applied to two-dimensional objects\"\n","\n","        assert len(self.scale_list) == len(self.estimator_list), \"the length of scale_list must equal to the length of estimator_list\"\n","        for scale_value in self.scale_list:\n","            scale_shape = numpy.array(scale_value).shape\n","            assert len(self.grid.shape) == len(scale_shape), \"the shape of scales must be similar to the shape of the data\"\n","            if len(self.grid.shape) == 1:\n","                assert scale_shape[0] < self.grid.shape[0], \"the scale must be smaller than the input data\"\n","            if len(self.grid.shape) == 2:\n","                assert (scale_shape[0] < self.grid.shape[0]) and (scale_shape[1] < self.grid.shape[1]), \"the scale must be smaller than the input data\"\n","\n","        assert type(outpath) == str, \"outpath should be string\"\n","        assert os.path.isdir(outpath), \"outpath should be a directory\"\n","\n","        if to_calculate_distance_matrices == True: \n","            assert distance_matrices_inpath == None, \"if to_calculate_distance_matrices=True, distance_matrices_inpath must be None\"\n","        if distance_matrices_inpath != None:\n","            assert (to_calculate_distance_matrices == False), \"if distance_matrices_inpath is not None, to_calculate_distance_matrices must be False\"\n","            assert type(distance_matrices_inpath) == str, \"distance_matrices_inpath path should be string\"\n","        \n","        if to_average_N_best_estimators == False: \n","            assert number_of_best_estimators == None, \"if to_average_N_best_estimators=False, number_of_best_estimators must be None\"\n","        if to_average_N_best_estimators == True:\n","            assert isinstance(number_of_best_estimators, int), \"if to_average_N_best_estimators=True, number_of_best_estimators must be an integer\"\n","\n","        self.outpath = outpath\n","        self.to_print_progress = to_print_progress\n","        self.to_calculate_distance_matrices = to_calculate_distance_matrices\n","        self.to_save_distance_matrices = to_save_distance_matrices\n","        self.distance_matrices_inpath = distance_matrices_inpath\n","        self.to_save_elongations = to_save_elongations\n","        self.to_average_N_best_estimators = to_average_N_best_estimators\n","        self.number_of_best_estimators = number_of_best_estimators\n","        self.to_use_parallelization = to_use_parallelization\n","\n","        ########################################################################################################\n","        ######### Parallelization                                                                    ###########\n","        ######################################################################################################## \n","        if self.to_use_parallelization:\n","            num_cores = multiprocessing.cpu_count()\n","            if self.to_print_progress:\n","                print(\"Parallelization is ON. Number of cores:\", num_cores)\n","\n","        ########################################################################################################\n","        ######### Output files                                                                       ###########\n","        ######################################################################################################## \n","        self.log_file_outpath = \"%s/log_file.txt\" % self.outpath\n","        self.distance_matrices_outpath = \"%s/distance_matrices.pkl\" % self.outpath\n","        self.elongations_outpath = \"%s/elongations.pkl\" % self.outpath\n","        self.weighted_distance_matrix_outpath = \"%s/weighted_distance_matrix.pkl\" % self.outpath\n","        self.sparse_distance_matrix_outpath = \"%s/sparse_distance_matrix.pkl\" % self.outpath\n","        self.final_products_outpath = \"%s/final_products.pkl\" % self.outpath\n","\n","        self.file_log = open(self.log_file_outpath, \"a\")\n","        self.file_log.write(\"started the run\\n\")\n","        self.file_log.flush()\n","\n","        ########################################################################################################\n","        ######### STEP 1: load or calculate distance matrices for different estimators and scales    ###########\n","        ########################################################################################################    \n","        if self.to_calculate_distance_matrices == False:\n","            distance_matrix_dictionary = self._load_distance_matrices_from_path()\n","\n","        else:\n","            distance_matrix_dictionary = self._return_distance_matrix_dictionary_for_estimators_and_scales()\n","            # save it if neccessary\n","            if self.to_save_distance_matrices == True:\n","                self._dump_distance_matrices_to_path(distance_matrix_dictionary)\n","                if self.to_print_progress:\n","                    print(\"dumped the distance matrix dictionaries to the file: %s\" % self.distance_matrices_outpath)\n","\n","        ########################################################################################################\n","        ######### STEP 2: order the spectra based on the different distance matrices, and measure    ###########\n","        #########         weights using the MST elongations.                                         ###########\n","        #########         Produce weighted distance matrix per scale and estimator.                  ###########    \n","        ######################################################################################################## \n","        self.weighted_elongation_and_sequence_dictionary = {}\n","        # the following lists will be used in STEP 3 for the proximity matrices\n","        MST_list = []\n","        weight_list = []\n","        distance_matrix_all = numpy.zeros((N_obj, N_obj))\n","\n","        if self.to_print_progress:\n","            print(\"strating to sequence the different scales and estimators\")\n","\n","        for estimator_index, estimator_name in enumerate(self.estimator_list):\n","            scale_list_for_estimator = self.scale_list[estimator_index]\n","            for scale_index, scale_value in enumerate(scale_list_for_estimator):\n","                if self.to_print_progress:\n","                    print(\"in estimator: %s, scale: %s\" % (estimator_name, scale_value))\n","\n","                distance_matrix_list = distance_matrix_dictionary[(estimator_name, scale_value)]\n","                weighted_distance_matrix, ordering_per_chunk_list, elongation_per_chunk_list = self._return_weighted_distance_matrix_for_single_estimator_and_scale(distance_matrix_list, to_return_elongation_list=True)\n","                # now obtain sequences from the weighted distance matrix\n","                ordering_bfs, ordering_dfs, mst_elongation, MST = self._apply_MST_and_return_BFS_DFS_ordering(weighted_distance_matrix, return_elongation=True, return_MST=True)\n","\n","                MST_list.append(MST)\n","                weight_list.append(mst_elongation)\n","                distance_matrix_all += (weighted_distance_matrix * mst_elongation)\n","                # add the sequences and their elongations into a dictionary\n","                self.weighted_elongation_and_sequence_dictionary[(estimator_name, scale_value, \"chunks\")] = (elongation_per_chunk_list, ordering_per_chunk_list)\n","                self.weighted_elongation_and_sequence_dictionary[(estimator_name, scale_value, \"weighted\")] = (mst_elongation, ordering_bfs)\n","\n","\n","        if self.to_save_elongations:\n","            f_elongations = open(self.elongations_outpath, \"wb\")\n","            pickle.dump(self.weighted_elongation_and_sequence_dictionary, f_elongations)\n","            f_elongations.close()\n","            if self.to_print_progress:\n","                print(\"dumped the elongations to the file: %s\" % self.elongations_outpath)\n","\n","        distance_matrix_all /= numpy.sum(weight_list)\n","        numpy.fill_diagonal(distance_matrix_all, 0) \n","        f_distance = open(self.weighted_distance_matrix_outpath, \"wb\")\n","        pickle.dump(distance_matrix_all, f_distance)\n","        f_distance.close()\n","        if self.to_print_progress:\n","            print(\"dumped the full weighted distance matrix to the file: %s\" % self.weighted_distance_matrix_outpath)\n","\n","        ########################################################################################################\n","        ######### STEP 3: use the elongations of the weighted distance matrices sequences            ###########\n","        #########         to build proximity matrices, then convert them to distance matrices,       ###########\n","        #########         and obtain the final BFS and DFS sequences.                                ###########    \n","        ######################################################################################################## \n","\n","        proximity_matrix_sparse = self._return_proximity_matrix_populated_by_MSTs_avg_prox(MST_list, weight_list)\n","        distance_matrix_sparse = self._convert_proximity_to_distance_matrix(proximity_matrix_sparse)\n","        ordering_bfs, ordering_dfs, mst_elongation, mst = self._apply_MST_and_return_BFS_DFS_ordering(distance_matrix_sparse, return_elongation=True, return_MST=True)\n","\n","        self.final_mst_elongation = mst_elongation\n","        self.final_mst = mst\n","        self.final_sequence = ordering_bfs\n","        ########################################################################################################\n","        ######### STEP 4: save the final BFS and DFS sequences, their final elongation, and          ###########\n","        #########         the sparse distance matrix that was used to obtain these.                  ###########\n","        ######################################################################################################## \n","        f_distance = open(self.sparse_distance_matrix_outpath, \"wb\")\n","        pickle.dump(distance_matrix_sparse, f_distance)\n","        f_distance.close()\n","        if self.to_print_progress:\n","            print(\"dumped the sparse distance matrix to the file: %s\" % f_distance)\n","\n","        final_sequences_dict = {'BFS': ordering_bfs, 'DFS': ordering_dfs}\n","        f_final_products = open(self.final_products_outpath, \"wb\")\n","        pickle.dump([mst_elongation, mst, final_sequences_dict], f_final_products)\n","        f_final_products.close()\n","        if self.to_print_progress:\n","            print(\"dumped the final sequences and elongation to the file: %s\" % f_final_products)\n","\n","        # remove the temporary directory and the temporary data if choice_parallelization=True\n","        if self.to_use_parallelization:\n","            folder = './joblib_memmap'\n","            shutil.rmtree(folder)\n","        \n","        return self.final_mst_elongation, self.final_sequence\n","\n","    def return_final_MST_elongation(self):\n","        \"\"\"Function returns the elongation of the final minimum spanning tree obtained after running the sequencer.\n","        This elongation serves as a figure of merit of the resulting sequence.\n","        \n","        Returns\n","        -------\n","        :param elongation: float, the elongation of the final minimum spanning tree.\n","        \"\"\"\n","        assert (self.final_mst_elongation != None), \"the elongation of the MST is not defined. Are you sure you executed the sequencer using Sequencer.execute first?\" \n","        return self.final_mst_elongation\n","\n","    def return_final_sequence(self):\n","        \"\"\"Function returns the final sequence obtained after running the sequencer. \n","        The sequence is a list containing the input indices, ordered according to the detected sequence. \n","        That is, if the list is: seq = [15, 64, 89, 3, ..], then the object at index 15 in the original data \n","        is the first in the sequence, the object at index 64 is the second in the sequence, and so on.\n","        \n","        Returns\n","        -------\n","        :param sequence: list of integers, the ordered indices of the input dataset according to the detected sequence.\n","        \"\"\"\n","        assert (self.final_sequence != None), \"the final sequence is not defined. Are you sure you executed the sequencer using Sequencer.execute first?\" \n","        return self.final_sequence\n","\n","    def return_final_MST(self):\n","        \"\"\"Function returns the final minimum spanning tree obtained after running the sequencer.\n","        \n","        Returns\n","        -------\n","        :param G: networkx.classes.graph.Graph(), the graph that represents the resulting MST.\n","        \"\"\"\n","        assert (self.final_mst != None), \"the final MST is not defined. Are you sure you executed the sequencer using Sequencer.execute first?\" \n","        return self.final_mst        \n","\n","\n","    def return_elongations_and_sequences_per_chunk(self, estimator_name, scale):\n","        \"\"\"Function returns the intermediate elongations and sequences obtained during the calculation of the final sequence.\n","        For each distance metric and scale, the sequencer divided each object into different chunks (parts), and estimated \n","        its corresponding sequence and elongation. This funciton returns a list of these elongations and sequences.\n","\n","        Parameters\n","        ----------\n","        :param estimator_name: string, the distance metric for which to return the list of elongations and sequences.\n","\n","        :param scale: integer, the scale for which toe return the list of elongations and sequences.\n","\n","\n","        Returns\n","        -------\n","        :param elongation_list: a list of float values, the list of elongations obtained for each of the chunks for the given \n","            distance metric and scale.\n","\n","        :param sequence_list: a list of lists, the list of sequences calculated for each of the chunks for the given \n","            distance metric and scale.\n","        \"\"\"\n","        assert (self.weighted_elongation_and_sequence_dictionary != None), \"the elongation and sequence dictionary is empty. Are you sure you executed the sequencer using Sequencer.execute first?\"\n","        assert (estimator_name in self.estimator_list), \"the required estimator is not included in the esitmator list\"\n","        for i, estimator_value in enumerate(self.estimator_list):\n","            if estimator_value == estimator_name:\n","                scale_list_for_estimator = self.scale_list[i]\n","                assert (scale in scale_list_for_estimator), \"the required scale is not included in the scale list for the given estimator\"\n","\n","        elongation_list, sequence_list = self.weighted_elongation_and_sequence_dictionary[(estimator_name, scale, \"chunks\")]\n","\n","        return elongation_list, sequence_list\n","\n","\n","    def return_elongation_of_weighted_products(self, estimator_name, scale):\n","        \"\"\"Function returns the intermediate elongations obtained in the second stage of the code. For each distance metric and\n","        scale, the sequencer estimated the weighted distance matrix, and used it to calculate a sequence and an elongation. \n","\n","        Parameters\n","        ----------\n","        :param estimator_name: string, the distance metric for which to return the list of elongations and sequences.\n","\n","        :param scale: integer, the scale for which toe return the list of elongations and sequences.\n","\n","\n","        Returns\n","        -------\n","        :param elongation: a float, the elongation that corresponds to the given metric and scale.\n","        \"\"\"\n","        assert (self.weighted_elongation_and_sequence_dictionary != None), \"the elongation and sequence dictionary is empty. Are you sure you executed the sequencer using Sequencer.execute first?\"\n","        assert (estimator_name in self.estimator_list), \"the required estimator is not included in the esitmator list\"\n","        for i, estimator_value in enumerate(self.estimator_list):\n","            if estimator_value == estimator_name:\n","                scale_list_for_estimator = self.scale_list[i]\n","                assert (scale in scale_list_for_estimator), \"the required scale is not included in the scale list for the given estimator\"   \n","\n","        elongation, sequence = self.weighted_elongation_and_sequence_dictionary[(estimator_name, scale, \"weighted\")]\n","\n","        return elongation\n","\n","\n","    def return_sequence_of_weighted_products(self, estimator_name, scale):\n","        \"\"\"Function returns the intermediate sequence obtained in the second stage of the code. For each distance metric and\n","        scale, the sequencer estimated the weighted distance matrix, and used it to calculate a sequence and an elongation. \n","\n","        Parameters\n","        ----------\n","        :param estimator_name: string, the distance metric for which to return the list of elongations and sequences.\n","\n","        :param scale: integer, the scale for which toe return the list of elongations and sequences.\n","\n","        Returns\n","        -------\n","        :param sequence: a list of integers, the sequence that corresponds to the given metric and scale.\n","        \"\"\"\n","        assert (self.weighted_elongation_and_sequence_dictionary != None), \"the elongation and sequence dictionary is empty. Are you sure you executed the sequencer using Sequencer.execute first?\"\n","        assert (estimator_name in self.estimator_list), \"the required estimator is not included in the esitmator list\"\n","        for i, estimator_value in enumerate(self.estimator_list):\n","            if estimator_value == estimator_name:\n","                scale_list_for_estimator = self.scale_list[i]\n","                assert (scale in scale_list_for_estimator), \"the required scale is not included in the scale list for the given estimator\"   \n","\n","        elongation, sequence = self.weighted_elongation_and_sequence_dictionary[(estimator_name, scale, \"weighted\")]\n","\n","        return sequence\n","\n","\n","    def return_elongation_of_weighted_products_all_metrics_and_scales(self):\n","        \"\"\"Function returns the intermediate elongations obtained in the second stage of the code. For each distance metric and\n","        scale, the sequencer estimated the weighted distance matrix, and used it to calculate a sequence and an elongation. \n","        (*) This function returns a list of elongations that corresponds to all the different metrics and scales. \n","        (*) If the user is interested in a particular metric and scale, then one can use the function: return_elongation_of_weighted_products.\n","\n","        Returns\n","        -------\n","        :param estimator_list: a list of strings, the distance metrics for which the elongations were calculated.\n","        :param scale_list: a list of integers, the scales for which the elongations were calculated.\n","        :param elongation_list: a list of floats, the elongations that corresponds to every metric and scale.\n","        \"\"\"\n","        assert (self.weighted_elongation_and_sequence_dictionary != None), \"the elongation and sequence dictionary is empty. Are you sure you executed the sequencer using Sequencer.execute first?\"\n","\n","        estimator_list = []\n","        scale_list = []\n","        elongation_list = []\n","        for estimator_index, estimator_value in enumerate(self.estimator_list):\n","            scale_list_for_estimator = self.scale_list[estimator_index]\n","            for scale_index, scale_value in enumerate(scale_list_for_estimator):\n","                elongation, sequence = self.weighted_elongation_and_sequence_dictionary[(estimator_value, scale_value, \"weighted\")]\n","\n","                estimator_list.append(estimator_value)\n","                scale_list.append(scale_value)\n","                elongation_list.append(elongation)\n","\n","        return estimator_list, scale_list, elongation_list\n","\n","\n","    def return_sequence_of_weighted_products_all_metrics_and_scales(self):\n","        \"\"\"Function returns the intermediate sequences obtained in the second stage of the code. For each distance metric and\n","        scale, the sequencer estimated the weighted distance matrix, and used it to calculate a sequence and an elongation. \n","        (*) This function returns a list of sequences that corresponds to all the different metrics and scales. \n","        (*) If the user is interested in a particular metric and scale, then one can use the function: return_sequence_of_weighted_products.\n","\n","        Returns\n","        -------\n","        :param estimator_list: a list of strings, the distance metrics for which the elongations were calculated.\n","        :param scale_list: a list of integers, the scales for which the elongations were calculated.\n","        :param sequence_list: a list of lists, the sequences that corresponds to every metric and scale.\n","        \"\"\"\n","        assert (self.weighted_elongation_and_sequence_dictionary != None), \"the elongation and sequence dictionary is empty. Are you sure you executed the sequencer using Sequencer.execute first?\"\n","\n","        estimator_list = []\n","        scale_list = []\n","        sequence_list = []\n","        for estimator_index, estimator_value in enumerate(self.estimator_list):\n","            scale_list_for_estimator = self.scale_list[estimator_index]\n","            for scale_index, scale_value in enumerate(scale_list_for_estimator):\n","                elongation, sequence = self.weighted_elongation_and_sequence_dictionary[(estimator_value, scale_value, \"weighted\")]\n","\n","                estimator_list.append(estimator_value)\n","                scale_list.append(scale_value)\n","                sequence_list.append(sequence)\n","\n","        return estimator_list, scale_list, sequence_list\n","\n","    #######################################################################################################################\n","    ################################################ PRIVATE FUNCTIONS ####################################################\n","    #######################################################################################################################\n","\n","    \n","    ###################################################### DATA I/O #######################################################\n","    def _load_distance_matrices_from_path(self):\n","        \"\"\"Funciton loads the distance matrices into memory from the distance matrix input file.\n","\n","        This is an internal function that is used only in a case where the distance matrices per metric and scale were already\n","        computed during a previous run, and were saved. In such a case, the user can choose to load the precomputed matrices\n","        instead of calculating them again. This can save a lot of execution time.\n","\n","        Returns\n","        -------\n","        :param distance_matrix_dictionary: a dictionary where each key is a tuple (estimator_name, scale_value), and the value \n","            is a list of distance matrices computed for each chunk of the data. \n","        \"\"\"\n","        input_file = open(self.distance_matrices_inpath, \"rb\")\n","        distance_matrix_dictionary_saved = pickle.load(input_file)\n","        input_file.close()\n","\n","        distance_matrix_dictionary = {}\n","        for estimator_index, estimator_value in enumerate(self.estimator_list):\n","\n","            scale_list_for_estimator = self.scale_list[estimator_index]\n","            for scale_value in scale_list_for_estimator:\n","                assert ((estimator_value, scale_value) in list(distance_matrix_dictionary_saved.keys())), \"the list of saved distance matrices does not include the required metrics and scales by Sequencer.execute\"\n","                distance_matrix_dictionary[(estimator_value, scale_value)] = distance_matrix_dictionary_saved[(estimator_value, scale_value)]\n","\n","        return distance_matrix_dictionary\n","\n","    def _dump_distance_matrices_to_path(self, distance_matrix_dictionary):\n","        \"\"\"Function saves the provided distance matrix dictionary into a file.\n","        \"\"\"\n","        output_file = open(self.distance_matrices_outpath, \"wb\")\n","        pickle.dump(distance_matrix_dictionary, output_file)\n","        output_file.close()\n","\n","\n","    ################################################# Distance measures ###################################################\n","    def _return_distance_matrix(self, grid, objects_list, estimator):\n","        \"\"\"Function estimates the distance matrix of the given objects using the given estimator.\n","\n","        Parameters\n","        -------\n","        :param grid: numpy.ndarray(), the x-axis of the objects in the sample\n","        :param objects_list: a list of numpy.ndarray(), the objects in the sample\n","        :param estimator: string, the name of the distance metric to use for the estimation of distance\n","\n","        Returns\n","        -------\n","        :param distance_matrix: numpy.ndarray(), the distance matrix \n","        \"\"\"\n","        grid = numpy.array(grid)\n","        objects_list = numpy.array(objects_list)\n","\n","        assert ((len(grid.shape) == 1) or (len(grid.shape) == 2)), \"objects can be 1 or 2 dimensional\"\n","        assert (~numpy.isnan(grid)).all(), \"grid cannot contain nan values\"\n","        assert (~numpy.isinf(grid)).all(), \"grid cannot contain infinite values\"\n","        assert (~numpy.isneginf(grid)).all(), \"grid cannot contain negative infinite values\"\n","        assert (~numpy.isnan(objects_list)).all(), \"objects_list cannot contain nan values\"\n","        assert (~numpy.isinf(objects_list)).all(), \"objects_list cannot contain infinite values\"\n","        assert (~numpy.isneginf(objects_list)).all(), \"objects_list cannot contain negative infinite values\"\n","        if len(grid.shape) == 1:\n","            assert (grid.shape[0] == objects_list.shape[1]), \"the grid and the objects must have the same dimensions\"\n","        if len(grid.shape) == 2:\n","            assert ((grid.shape[0] == objects_list.shape[1]) and (grid.shape[1] == objects_list.shape[2])), \"the grid and the objects must have the same dimensions\"\n","        assert estimator in ['EMD', 'energy', 'KL', 'L2'], \"the distance estimator must be: EMD, energy, KL, or L2\"\n","        if estimator == \"EMD\":\n","            assert (objects_list >= 0).all(), \"the EMD distance can only be applied to non-negative values\"\n","        if estimator == \"energy\":\n","            assert (objects_list >= 0).all(), \"the energy distance can only be applied to non-negative values\"\n","        if estimator == \"KL\":\n","            assert (objects_list > 0).all(), \"the KL distance can only be applied to positive values\"\n","\n","        # if the distance claculation should be carried out in parallel, save the data that will be used\n","        if self.to_use_parallelization:\n","            folder = './joblib_memmap'\n","            try:\n","                os.mkdir(folder)\n","            except FileExistsError:\n","                pass\n","\n","            data_filename_memmap = os.path.join(folder, 'data_memmap')\n","            dump(objects_list, data_filename_memmap)\n","            objects_list = load(data_filename_memmap, mmap_mode='r')\n","\n","            grid_filename_memmap = os.path.join(folder, 'grid_memmap')\n","            dump(grid, grid_filename_memmap)\n","            grid = load(grid_filename_memmap, mmap_mode='r')\n","\n","        if estimator == \"EMD\":\n","            distance_matrix = return_emd_mat_brute_force(grid, objects_list, self.to_use_parallelization)\n","\n","        if estimator == \"energy\":\n","            distance_matrix = return_energy_mat(grid, objects_list, self.to_use_parallelization)\n","\n","        if estimator == \"KL\":\n","            distance_matrix = return_kl_mat(objects_list, self.to_use_parallelization)\n","\n","        if estimator == \"L2\":\n","            distance_matrix = return_L2_mat(objects_list, self.to_use_parallelization)\n","\n","        return distance_matrix\n","\n","    ################################################## Scale functions ####################################################\n","    def _normalise_objects(self, objects_list):\n","        \"\"\"Function normalizes each of the objects in the list such that the sum of its elements will be one.\n","\n","        Parameters\n","        -------\n","        :param objects_list: a list of numpy.ndarray(), the objects in the sample\n","\n","        Returns\n","        -------\n","        :param objects_list: a list of numpy.ndarray(), the normalized objects\n","        \"\"\"\n","        assert ((len(objects_list.shape) == 2) or (len(objects_list.shape) == 3)), \"objects can be either 1D or 2D\"\n","\n","        if len(objects_list.shape) == 2:\n","            sum_vector = numpy.sum(objects_list, axis=1)\n","            objects_list_normalised = objects_list / sum_vector[:, numpy.newaxis]\n","\n","        if len(objects_list.shape) == 3:\n","            sum_vector = numpy.sum(objects_list, axis=(1,2))\n","            objects_list_normalised = objects_list / sum_vector[:, numpy.newaxis, numpy.newaxis]\n","\n","        return objects_list_normalised\n","\n","    def _divide_to_chunks_1D(self, grid, objects_list, N_chunks):\n","        \"\"\"Function divides the data into chunks according to N_chunks, and then normalizes each chunk to have a sum of one.\n","        Function also splits the grid array into the same chunks. Function assumes that the grid is 1D and the object list \n","        is 2D.\n","\n","        Parameters\n","        -------\n","        :param grid: numpy.ndarray(), the x-axis of the objects\n","        :param objects_list: a list of numpy.ndarray(), the objects in the sample\n","        :param N_chunks: integer, the number of chunks to split each object into\n","\n","        Returns\n","        -------\n","        :param grid_split: a list of numpy.ndarray(), a list containing the different parts of the split grid\n","        :param objects_list_split_normalised: a list of numpy.ndarray(), a list of length N_chunks consisting of the \n","            objects_list for each chunk, after normalization\n","        \"\"\"\n","        grid_split = numpy.array_split(grid, N_chunks)\n","        objects_list_split = numpy.array_split(objects_list, N_chunks, axis=-1)\n","        objects_list_split_normalised = []\n","        for objects_list_chunk in objects_list_split:\n","            sum_vec = numpy.sum(objects_list_chunk, axis=-1)\n","            for sum_val in sum_vec:\n","                assert (sum_val > 0), \"during the splitting into chunks, a chunk resulted in a negative or zero sum, which means that the chunk cannot be normalized. The user should consider adding an offset to all the objects\"\n","            object_list_chunk_norm = objects_list_chunk / sum_vec[:, numpy.newaxis]\n","            objects_list_split_normalised.append(object_list_chunk_norm)\n","                \n","        return grid_split, objects_list_split_normalised\n","\n","    def _divide_to_chunks_2D(self, grid, objects_list, N_chunks):\n","        \"\"\"Function divides the data into chunks according to N_chunks, and then normalizes each chunk to have a sum of one.\n","        Function also splits the grid array into the same chunks. Function assumes that the grid is 2D and the object list \n","        is 3D.\n","\n","        Parameters\n","        -------\n","        :param grid: numpy.ndarray(), the x-axis of the objects\n","        :param objects_list: a list of numpy.ndarray(), the objects in the sample\n","        :param N_chunks: integer, the number of chunks to split each object into\n","\n","        Returns\n","        -------\n","        :param grid_split: a list of numpy.ndarray(), a list containing the different parts of the split grid\n","        :param objects_list_split_normalised: a list of numpy.ndarray(), a list of length N_chunks consisting of the \n","            objects_list for each chunk, after normalization\n","        \"\"\"\n","        grid_split = []\n","        for grid_split_tmp in numpy.array_split(grid, N_chunks[0], axis=0):\n","            grid_split += numpy.array_split(grid_split_tmp, N_chunks[1], axis=1)\n","        \n","        objects_list_split_normalised = []\n","        objects_list_split_1 = numpy.array_split(objects_list, N_chunks[0], axis=1)\n","        for objects_list_split_tmp in objects_list_split_1:\n","            objects_list_split_2 = numpy.array_split(objects_list_split_tmp, N_chunks[1], axis=2)\n","            for objects_list_split in objects_list_split_2:\n","                sum_vec = numpy.sum(objects_list_split, axis=(1,2))\n","                for sum_val in sum_vec:\n","                    assert (sum_val > 0), \"during the splitting into chunks, a chunk resulted in a negative or zero sum, which means that the chunk cannot be normalized. The user should consider adding an offset to all the objects\"\n","                objects_list_split_normalised.append(objects_list_split / sum_vec[:, numpy.newaxis, numpy.newaxis])\n","                \n","        return grid_split, objects_list_split_normalised\n","\n","    def _divide_to_chunks(self, grid, objects_list, N_chunks):\n","        \"\"\"The main function that divides the data into chunks. It splits the grid and objects_list into chunks\n","        according to N_chunks. The function does not assume that N_chunks can divide the data into equaly-sized chunks, \n","        but instead returns chunks of roughly similar size.\n","\n","        Parameters\n","        -------\n","        :param grid: numpy.ndarray(), the x-axis of the objects\n","        :param objects_list: a list of numpy.ndarray(), the objects in the sample\n","        :param N_chunks: integer, the number of chunks to split each object into\n","\n","        Returns\n","        -------\n","        :param grid_split: a list of numpy.ndarray(), a list containing the different parts of the split grid\n","        :param objects_list_split_normalised: a list of numpy.ndarray(), a list of length N_chunks consisting of the \n","            objects_list for each chunk, after normalization\n","        \"\"\"\n","        assert ((len(grid.shape) == 1) or (len(grid.shape) == 2)), \"objects can be either 1D or 2D\"\n","\n","        if len(grid.shape) == 1:\n","            return self._divide_to_chunks_1D(grid, objects_list, N_chunks)\n","        if len(grid.shape) == 2:\n","            return self._divide_to_chunks_2D(grid, objects_list, N_chunks)\n","\n","\n","    ################################################## GRAPH FUNCTIONS ####################################################\n","    def _return_MST_elongation(self, distance_arr):\n","        \"\"\"Function estimates the elongation of the MST that is described by the given distance array. The input distance \n","        array represents the distances of each node in the graph from the root of the graph (the starting point). \n","        Funciton calculates the elongation by dividing the half-length of the tree by the half-width.\n","        The half-width is calculated as the average width in every depth level, and the half-length is calculated as the\n","        average distance from the root.\n","\n","        Parameters\n","        -------\n","        :param distance_arr: list, a list that described the distance of each node from the root of the tree\n","\n","        Returns\n","        -------\n","        :param mst_elongation: float, the elongation of the MST\n","        \"\"\"\n","        graph_half_length = numpy.average(distance_arr) \n","        g_unique, counts = numpy.unique(distance_arr, return_counts=True)\n","        graph_half_width = numpy.average(counts) / 2.\n","        mst_elongation = float(graph_half_length) / float(graph_half_width) + 1 \n","\n","        return mst_elongation\n","\n","    def _return_start_index_from_MST(self, graph):\n","        \"\"\"Function returns the starting point of the sequence, which is defined as the least central node in the given graph.\n","        The least central node in the graph is defined using the closeness centrality.\n","        \n","        Parameters\n","        -------\n","        :param graph: networkx.classes.graph.Graph(), the graph that represents the Mininun Spanning Tree\n","\n","        Returns\n","        -------\n","        :param start_index: integer, the index of the node found to be the starting point\n","        \"\"\"\n","        centrality = nx.closeness_centrality(graph)\n","        indices = numpy.fromiter(centrality.keys(), dtype=int)\n","        centrality_measure = numpy.fromiter(centrality.values(), dtype=float)\n","        start_index = indices[numpy.argmin(centrality_measure)]\n","\n","        return start_index\n","\n","    def _apply_MST_and_return_MST_and_elongation(self, distance_matrix, return_elongation=True):\n","        \"\"\"Function converts the distance matrix into a fully-conncted graph and calculates its Minimum Spanning Tree (MST).\n","        Function has an option to return the elongation of the resulting MST. \n","\n","        Parameters\n","        -------\n","        :param distance_matrix: numpy.ndarray(), the distance matrix that will be converted into an MST.\n","        :param return_elongation: boolean (default=True), whether to return the elongation of the resulting MST.\n","\n","        Returns\n","        -------\n","        :param G: networkx.classes.graph.Graph(), the graph that represents the resulting MST.\n","        :param mst_elongation (optional): float, the elongation of the resulting MST.\n","        \"\"\"\n","        assert type(distance_matrix) == numpy.ndarray, \"distance matrix must be numpy.ndarray\"\n","        assert len(distance_matrix.shape) == 2, \"distance matrix must have 2 dimensions\"\n","        assert distance_matrix.shape[0] == distance_matrix.shape[1], \"distance matrix must be NxN matrix\"\n","        assert (~numpy.isnan(distance_matrix)).all(), \"distance matrix contains nan values\"\n","        assert (~numpy.isneginf(distance_matrix)).all(), \"distance matrix contains negative infinite values\"\n","        assert (distance_matrix.round(5) >= 0).all(), \"distance matrix contains negative values\"\n","        assert (distance_matrix.diagonal() == 0).all(), \"distance matrix must contain zeros in its diagonal\"\n","\n","        min_span_dist_mat = minimum_spanning_tree(csr_matrix(distance_matrix)).toarray()\n","        G = nx.from_scipy_sparse_matrix(minimum_spanning_tree(csr_matrix(distance_matrix)))\n","        if return_elongation:\n","            start_index = self._return_start_index_from_MST(G)\n","            distance_dict = nx.shortest_path_length(G, start_index)\n","            distance_arr = numpy.fromiter(distance_dict.values(), dtype=int)\n","            mst_elongation = self._return_MST_elongation(distance_arr)\n","            return G, mst_elongation\n","        else:\n","            return G\n","\n","    def _apply_MST_and_return_BFS_DFS_ordering(self, distance_matrix, start_index=None, return_elongation=True, return_MST=True):\n","        \"\"\"Function converts the distance matrix into a fully-connected graph and calculates its minimum spanning tree (MST).\n","        The function also returns two walks within the tree: BFS and DFS. The function also has an option to return the axis \n","        ratio of the resulting MST.\n","\n","        Parameters\n","        -------\n","        :param distance_matrix: numpy.ndarray(), the distance matrix that will be converted into an MST.\n","        :param start_index: integer (default=None), the index in the matrix from which to start the BFS/DFS walk within the MST. \n","            If start_index==None, the function estimates the staring point using the closeness centrality measure.\n","        :param return_elongation: boolean (default=True), whether to return the elongation of the resulting MST.\n","        :param return MST: boolean (default=True), whether to return the resulting MST.\n","\n","        Returns\n","        -------\n","        :param ordering_bfs: a list of integers, a list representing the indices of the nodes according to a BFS walk in the MST\n","        :param ordering_dfs: a list of integers, a list representing the indices of the nodes according to a DFS walk in the MST\n","        :param mst_elongation (optional): float, the elongation of the resulting MST.\n","        :param G (optional): networkx.classes.graph.Graph(), the graph that represents the resulting MST.\n","        \"\"\"\n","        assert type(distance_matrix) == numpy.ndarray, \"distance matrix must be numpy.ndarray\"\n","        assert len(distance_matrix.shape) == 2, \"distance matrix must have 2 dimensions\"\n","        assert distance_matrix.shape[0] == distance_matrix.shape[1], \"distance matrix must be NxN matrix\"\n","        assert (~numpy.isnan(distance_matrix)).all(), \"distance matrix contains nan values\"\n","        assert (~numpy.isneginf(distance_matrix)).all(), \"distance matrix contains negative infinite values\"\n","        assert (distance_matrix.round(5) >= 0).all(), \"distance matrix contains negative values\"\n","        assert (distance_matrix.diagonal() == 0).all(), \"distance matrix must contain zeros in its diagonal\"\n","\n","        min_span_dist_mat = minimum_spanning_tree(csr_matrix(distance_matrix)).toarray()\n","        G = nx.from_scipy_sparse_matrix(minimum_spanning_tree(csr_matrix(distance_matrix)))\n","        if start_index == None:\n","            start_index = self._return_start_index_from_MST(G)\n","        # DFS walk\n","        ordering_dfs = numpy.fromiter(nx.dfs_preorder_nodes(G, start_index), dtype=int)\n","        # BFS walk\n","        ordering_bfs = self._return_bfs_walk(G, start_index)\n","\n","        if return_elongation and return_MST:\n","            distance_dict = nx.shortest_path_length(G, start_index)\n","            distance_arr = numpy.fromiter(distance_dict.values(), dtype=int)\n","            mst_elongation = self._return_MST_elongation(distance_arr)\n","            return ordering_bfs, ordering_dfs, mst_elongation, G\n","        elif return_elongation:\n","            distance_dict = nx.shortest_path_length(G, start_index)\n","            distance_arr = numpy.fromiter(distance_dict.values(), dtype=int)\n","            mst_elongation = self._return_MST_elongation(distance_arr)\n","            return ordering_bfs, ordering_dfs, mst_elongation\n","        else:\n","            return ordering_bfs, ordering_dfs\n","\n","    def _return_bfs_walk(self, G, start_index):\n","        \"\"\"Function returns the BFS walk within the given graph, assuming the given starting index. The difference \n","        between this function and the function in networkx is that this function takes into account the distances between\n","        individual nodes when performing the walk. When there is a degeneracy and one can walk to several nodes, the \n","        nodes will be visited according to their distance from their predecessor.\n","\n","        Parameters\n","        -------\n","        :param G: networkx.classes.graph.Graph(), the graph that represents the resulting MST.\n","        :param start_index: integer (default=None), the index in the matrix from which to start the walk within the MST. \n","\n","        Returns\n","        -------\n","        :param ordering_bfs: a list of integers, a list representing the indices of the nodes according to a BFS walk in the MST\n","        \"\"\"\n","        distance_dict = nx.shortest_path_length(G, start_index)\n","        bfs_pred = dict(nx.bfs_predecessors(G, start_index))\n","\n","        distance_inds = numpy.fromiter(distance_dict.keys(), dtype=int)\n","        distance_arr = numpy.fromiter(distance_dict.values(), dtype=int)\n","\n","        ordering_bfs = []\n","        distance_arr_unique = numpy.unique(distance_arr)\n","        for dist_val in distance_arr_unique:\n","            distance_inds_small = numpy.array(distance_inds[distance_arr == dist_val])\n","            # no degeneracy - a single node ahead\n","            if len(distance_inds_small) == 1:\n","                ordering_bfs.append(distance_inds_small[0])\n","            # degeneracy - several nodes, need to order them according to distance\n","            else:\n","                distance_arr_small = []\n","                for curr_ind in distance_inds_small:\n","                    prev_ind = bfs_pred[curr_ind]\n","                    distance_arr_small.append(G[prev_ind][curr_ind]['weight'])\n","                distance_arr_small = numpy.array(distance_arr_small)\n","                inds_ordered = distance_inds_small[numpy.argsort(distance_arr_small)]\n","                ordering_bfs += list(inds_ordered)\n","\n","        ordering_bfs = numpy.array(ordering_bfs).astype(numpy.int)\n","        return ordering_bfs\n","\n","\n","    ######################################## PROXIMIY/DISTANCE matrix conversion ##########################################\n","    def _return_proximity_matrix_populated_by_MSTs_avg_prox(self, MST_list, weight_list):\n","        \"\"\"Function populates the MSTs from the input list into a proximty matrix, where each MST is weighted according \n","        to the appropriate weight from the weight list. The population is done by inserting the edges in an MST into \n","        the relevant cells in the proximity matrix, weighted by the appropriate weight.\n","        (*) Cells in the matrix that do not correspond to any edge will be filled with zero (no proximity).\n","        (*) Cells in the diagonal of the matrix will be filled with numpy.inf (infinite proximity).\n","\n","        Parameters\n","        -------\n","        :param MST_list: list of networkx.classes.graph.Graph(), a list of the MSTs to be populated into the proximity matrix.\n","        :param weight_list: list of floats, a list of the weights of each of the MST when populated into the proximity matrix.\n","            In practice, the weights are defined as the elongations of each of the MSTs.\n","\n","        Returns\n","        -------\n","        :param proximity_matrix: numpy.ndarray(), the proximity matrix, populated by the different MSTs.\n","        \"\"\"\n","        assert type(MST_list) == list, \"MST_list should be a list\"\n","        assert (numpy.array(weight_list) >= 0).all(), \"weights in weight_list should be non-negative\"\n","        assert numpy.fromiter([type(mst) == nx.classes.graph.Graph for mst in MST_list], dtype=bool).all(), \"MST_list should contain networkx.classes.graph.Graph objects\"\n","\n","        # take only the N best estimators, if required:\n","        if self.to_average_N_best_estimators:\n","            indices = numpy.argsort(weight_list)[::-1][:self.number_of_best_estimators]\n","            weight_list_new = []\n","            MST_list_new = []\n","            for index_good in indices:\n","                weight_list_new.append(weight_list[index_good])\n","                MST_list_new.append(MST_list[index_good])\n","\n","            weight_list = list(weight_list_new)\n","            MST_list = list(MST_list_new)\n","\n","        N = MST_list[0].number_of_nodes()\n","        sum_of_weights = numpy.sum(weight_list)\n","        proximity_matrix = numpy.zeros((N, N))\n","\n","        for mst_index, mst in enumerate(MST_list):\n","            weight_of_mst = weight_list[mst_index]\n","            # go over all the edges and populate, this should be symmetric\n","            for edge in mst.edges():\n","                node1 = edge[0]\n","                node2 = edge[1]\n","                distance = mst[node1][node2]['weight']\n","                proximity_matrix[node1, node2] += (weight_of_mst * (1.0 / distance))\n","                proximity_matrix[node2, node1] += (weight_of_mst * (1.0 / distance))\n","        proximity_matrix /= sum_of_weights\n","        numpy.fill_diagonal(proximity_matrix, numpy.inf)\n","        return proximity_matrix\n","\n","    def _return_proximity_matrix_populated_by_MSTs_avg_dist(self, MST_list, weight_list):\n","        \"\"\"Function populates the MSTs from the input list into a proximty matrix, where each MST is weighted according \n","        to the appropriate weight from the weight list. The population is done by inserting the edges in an MST into \n","        the relevant cells in the distance matrix (the inverse of the proximity matrix), weighted by the appropriate weight.\n","        (*) Cells in the matrix that do not correspond to any edge will be filled with zero (no proximity).\n","        (*) Cells in the diagonal of the matrix will be filled with numpy.inf (infinite proximity).\n","\n","        Parameters\n","        -------\n","        :param MST_list: list of networkx.classes.graph.Graph(), a list of the MSTs to be populated into the proximity matrix.\n","        :param weight_list: list of floats, a list of the weights of each of the MST when populated into the proximity matrix.\n","            In practice, the weights are defined as the elongations of each of the MSTs.\n","\n","        Returns\n","        -------\n","        :param proximity_matrix: numpy.ndarray(), the proximity matrix, populated by the different MSTs.\n","        \"\"\"\n","        assert type(MST_list) == list, \"MST_list should be a list\"\n","        assert (numpy.array(weight_list) >= 0).all(), \"weights in weight_list should be non-negative\"\n","        assert numpy.fromiter([type(mst) == nx.classes.graph.Graph for mst in MST_list], dtype=bool).all(), \"MST_list should contain networkx.classes.graph.Graph objects\"\n","\n","        # take only the N best estimators, if required:\n","        if self._to_average_N_best_estimators:\n","            indices = numpy.argsort(weight_list)[::-1][:self.number_of_best_estimators]\n","            weight_list_new = []\n","            MST_list_new = []\n","            for index_good in indices:\n","                weight_list_new.append(weight_list[index_good])\n","                MST_list_new.append(MST_list[index_good])\n","\n","            weight_list = list(weight_list_new)\n","            MST_list = list(MST_list_new)\n","\n","        N = MST_list[0].number_of_nodes()\n","        sum_of_weights = numpy.sum(weight_list)\n","        distance_matrix = numpy.zeros((N, N))\n","\n","        for mst_index, mst in enumerate(MST_list):\n","            weight_of_mst = weight_list[mst_index]\n","            # go over all the edges and populate, this should be symmetric\n","            for edge in mst.edges():\n","                node1 = edge[0]\n","                node2 = edge[1]\n","                distance = mst[node1][node2]['weight']\n","                distance_matrix[node1, node2] += (weight_of_mst * distance)\n","                distance_matrix[node2, node1] += (weight_of_mst * distance)\n","\n","        # now convert the distance matrix into a proximity matrix\n","        proximity_matrix = self._convert_distance_to_proximity_matrix(distance_matrix)\n","        return proximity_matrix\n","\n","\n","    def _convert_proximity_to_distance_matrix(self, proximity_matrix):\n","        \"\"\"Function converts the given proximity matrix into a distance matrix and returns it.\n","\n","        Parameters\n","        -------\n","        :param proximity_matrix: numpy.ndarray(), a matrix describing the proximity between the different objects\n","\n","        Returns\n","        -------\n","        :param distance_matrix: numpy.ndarray(), a matrix describing the distance between the different objects. \n","            It contains values which are the inverse of the proximity values.\n","        \"\"\"\n","        assert type(proximity_matrix) == numpy.ndarray, \"proximity matrix must be numpy.ndarray\"\n","        assert len(proximity_matrix.shape) == 2, \"proximity matrix must have 2 dimensions\"\n","        assert proximity_matrix.shape[0] == proximity_matrix.shape[1], \"proximity matrix must be NxN matrix\"\n","        assert (~numpy.isnan(proximity_matrix)).all(), \"proximity matrix contains nan values\"\n","        assert (~numpy.isneginf(proximity_matrix)).all(), \"proximity matrix contains negative infinite values\"\n","        assert (proximity_matrix >= 0).all(), \"proximity matrix contains negative values\"\n","\n","        proximity_matrix_copy = numpy.copy(proximity_matrix)\n","        numpy.fill_diagonal(proximity_matrix_copy, numpy.inf)\n","        distance_matrix = 1.0 / proximity_matrix_copy\n","        return distance_matrix\n","\n","    def _convert_distance_to_proximity_matrix(self, distance_matrix):\n","        \"\"\"Function converts the given distance matrix into a proximity matrix and returns it.\n","\n","        Parameters\n","        -------\n","        :param distance_matrix: numpy.ndarray(), a matrix describing the distances between the different objects.\n","\n","        Returns\n","        -------\n","        :param proximity_matrix: numpy.ndarray(), a matrix describing the proximity between the different objects. \n","            It contains values which are the inverse of the distance values.\n","        \"\"\"\n","        assert type(distance_matrix) == numpy.ndarray, \"distance matrix must be numpy.ndarray\"\n","        assert len(distance_matrix.shape) == 2, \"distance matrix must have 2 dimensions\"\n","        assert distance_matrix.shape[0] == distance_matrix.shape[1], \"distance matrix must be NxN matrix\"\n","        assert (~numpy.isnan(distance_matrix)).all(), \"distance matrix contains nan values\"\n","        assert (~numpy.isneginf(distance_matrix)).all(), \"distance matrix contains negative infinite values\"\n","        assert (distance_matrix.round(5) >= 0).all(), \"distance matrix contains negative values\"\n","\n","        distance_matrix_copy = numpy.copy(distance_matrix)\n","        numpy.fill_diagonal(distance_matrix_copy, 0)\n","        proximity_matrix = 1.0 / distance_matrix_copy\n","        return proximity_matrix\n","\n","    ################################################ ALGORITHM FUNCTIONS ##################################################\n","    def _return_distance_matrix_dictionary_for_estimators_and_scales(self):\n","        \"\"\"Function calculates the distance matrices for each distance metric and scale. \n","        It uses the list of distance metrics and scales provided by the user. For each metric and scale, function divides \n","        the objects into chunks according to the scale, and estimates the distance between the chunks of objects.\n","    \n","        Returns\n","        -------\n","        :param distance_matrix_dictionary: dict(), a dictionary consisting of all the different distance matrices. The keys \n","            of the dictionary are tuples of (estimator_name, scale_value), where estimator_name is a given distance metric\n","            and scale_value is a given scale. The values of the dictionary are lists consisting of the distance matrices \n","            for eahc of the chunks.\n","        \"\"\"\n","        assert type(self.grid) == numpy.ndarray, \"grid must be numpy.ndarray\"\n","        assert type(self.objects_list) == numpy.ndarray, \"objects_list_normalised must be numpy.ndarray\"\n","        assert ((len(self.grid.shape) == 1) or (len(self.grid.shape) == 2)), \"objects can be 1 or 2 dimensional\"\n","        assert (~numpy.isnan(self.grid)).all(), \"grid cannot contain nan values\"\n","        assert (~numpy.isinf(self.grid)).all(), \"grid cannot contain infinite values\"\n","        assert (~numpy.isneginf(self.grid)).all(), \"grid cannot contain negative infinite values\"\n","        assert (~numpy.isnan(self.objects_list)).all(), \"objects_list cannot contain nan values\"\n","        assert (~numpy.isinf(self.objects_list)).all(), \"objects_list cannot contain infinite values\"\n","        assert (~numpy.isneginf(self.objects_list)).all(), \"objects_list cannot contain negative infinite values\"\n","        if len(self.grid.shape) == 1:\n","            assert (self.grid.shape[0] == self.objects_list.shape[1]), \"the grid and the objects must have the same dimensions\"\n","        if len(self.grid.shape) == 2:\n","            assert ((self.grid.shape[0] == self.objects_list.shape[1]) and (self.grid.shape[1] == self.objects_list.shape[2])), \"the grid and the objects must have the same dimensions\"\n","        assert numpy.fromiter([(isinstance(scale_value, int) or type(scale_value) == numpy.int64) for scale_value in numpy.array(self.scale_list).flatten()], dtype=bool).all(), \"scale values must all be integers\"\n","        assert numpy.fromiter([estimator_value in ['EMD', 'energy', 'KL', 'L2'] for estimator_value in self.estimator_list], dtype=bool).all(), \"estimators must be EMD, energy, KL or L2\"\n","\n","        distance_matrix_dictionary = {}\n","        for estimator_index, estimator_name in enumerate(self.estimator_list):\n","\n","            scale_list_for_estimator = self.scale_list[estimator_index]\n","            for scale_index, scale_value in enumerate(scale_list_for_estimator):\n","\n","                # printing information and saving it into a log file\n","                if self.to_print_progress:\n","                    print(\"calculating the distance matrices for estimator: %s, scale: %s\" % (estimator_name, scale_value))\n","                if self.file_log != None:\n","                    self.file_log.write(\"calculating the distance matrices for estimator: %s, scale: %s\\n\" % (estimator_name, scale_value))\n","                    self.file_log.flush()\n","                \n","                start_time = time.time()\n","                # divide the objects into chunks according to the scale\n","                N_chunks = scale_value\n","                grid_splitted, objects_list_splitted = self._divide_to_chunks(self.grid, numpy.copy(self.objects_list), N_chunks)\n","                # construct the distance matrix list for this given scale\n","                distance_matrix_list = []\n","                for i in range(len(grid_splitted)):\n","                    grid_of_chunk = grid_splitted[i]\n","                    objects_list_of_chunk = objects_list_splitted[i]\n","                    distance_matrix_of_chunk = self._return_distance_matrix(grid_of_chunk, objects_list_of_chunk, estimator_name)\n","                    distance_matrix_list.append(distance_matrix_of_chunk)\n","\n","                if self.to_print_progress: \n","                    print(\"finished calculating this distance matrix list, it took: %s seconds\" % str(time.time() - start_time))\n","                if self.file_log != None:\n","                    self.file_log.write(\"finished calculating this distance matrix list, it took: %s seconds \\n\" % str(time.time() - start_time))\n","                    self.file_log.flush()\n","\n","                # add the list of matrices to the dictionary\n","                distance_matrix_dictionary[(estimator_name, scale_value)] = distance_matrix_list\n","        return distance_matrix_dictionary\n","\n","    def _return_weighted_distance_matrix_for_single_estimator_and_scale(self, distance_matrix_list, to_return_elongation_list=True, to_return_sequence_list=True):\n","        \"\"\"Function calculates the weighted distance matrix for a single metric and scale. \n","        Function takes as an input a list of distance matrices, which correspond to the different chunks at a given scale.\n","        Function orders the spectra according to each chunk and measures the elongation which serves as a weight of each sequence.\n","        Function then performs a weighted average to return a single distance matrix, according to the elongation.\n","\n","        Parameters\n","        -------\n","        :param distance_matrix_list: list of numpy.ndarray(), a list of distance matrices for each chunk.\n","        :param to_return_elongation_list: boolean (default=True), whether to return a list of elongations per chunk.\n","        :param to_return_sequence_list: boolean (default=True), whether to return a list of the sequences per chunk.\n","\n","        Returns\n","        -------\n","        :param weighted_distance_matrix: numpy.ndarray(), the weighted distance matrix over the different chunks\n","        :param ordering_list (optional): list of lists, a list that contains the sequences for each different chunk\n","        :param elongation_list (optional): list of floats, a list that contains the elongations for each different chunk\n","        \"\"\"\n","        assert type(distance_matrix_list) == list, \"distance_matrix_list must be a list\"\n","        for distance_matrix in distance_matrix_list:\n","            assert type(distance_matrix) == numpy.ndarray, \"distance matrix must be numpy.ndarray\"\n","            assert len(distance_matrix.shape) == 2, \"distance matrix must have 2 dimensions\"\n","            assert distance_matrix.shape[0] == distance_matrix.shape[1], \"distance matrix must be NxN matrix\"\n","            assert (~numpy.isnan(distance_matrix)).all(), \"distance matrix contains nan values\"\n","            assert (~numpy.isinf(distance_matrix)).all(), \"distance matrix contains infinite values\"\n","            assert (~numpy.isneginf(distance_matrix)).all(), \"distance matrix contains negative infinite values\"\n","            assert (distance_matrix.round(5) >= 0).all(), \"distance matrix contains negative values\"\n","            assert (numpy.diagonal(distance_matrix) == 0).all(), \"distance matrix must contain zero values in its diagonal\"\n","\n","        elongation_list = []\n","        ordering_list = []\n","        for chunk_index in range(len(distance_matrix_list)):\n","            distance_matrix_of_chunk = distance_matrix_list[chunk_index]\n","            ordering_bfs, ordering_dfs, mst_elongation, mst = self._apply_MST_and_return_BFS_DFS_ordering(distance_matrix_of_chunk, return_elongation=True, return_MST=True)\n","            elongation_list.append(mst_elongation)\n","            ordering_list.append(ordering_bfs)\n","        elongation_list = numpy.array(elongation_list)\n","\n","        # now take the weighted average to the list according to the weights you calculated\n","        weighted_distance_matrix = numpy.average(distance_matrix_list, axis=0, weights=elongation_list)\n","        if to_return_elongation_list and to_return_sequence_list:\n","            return weighted_distance_matrix, ordering_list, elongation_list\n","        elif to_return_elongation_list and not to_return_sequence_list:\n","            return weighted_distance_matrix, ordering_list\n","        else:\n","            return weighted_distance_matrix\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","#######################################################################################################################\n","#######################################################################################################################\n","#######################################################################################################################\n","#######################################################################################################################\n","####################################################### ENLONGATION ESTIMATION ########################################\n","#######################################################################################################################\n","#######################################################################################################################\n","####################################################### IMPORTS #######################################################\n","#######################################################################################################################\n","\n","import numpy\n","import time\n","import networkx as nx\n","from scipy.sparse import csr_matrix\n","from scipy.sparse.csgraph import minimum_spanning_tree\n","\n","def return_start_index_from_MST(graph):\n","    \"\"\"Function returns the starting point of the sequence, which is defined as the least central node in the given graph.\n","    The least central node in the graph is defined using the closeness centrality.\n","    \n","    Parameters\n","    -------\n","    :param graph: networkx.classes.graph.Graph(), the graph that represents the Mininun Spanning Tree\n","\n","    Returns\n","    -------\n","    :param start_index: integer, the index of the node found to be the starting point\n","    \"\"\"\n","    centrality = nx.closeness_centrality(graph)\n","    indices = numpy.fromiter(centrality.keys(), dtype=int)\n","    centrality_measure = numpy.fromiter(centrality.values(), dtype=float)\n","    start_index = indices[numpy.argmin(centrality_measure)]\n","\n","    return start_index\n","\n","def return_MST_elongation(distance_arr):\n","    \"\"\"Function estimates the elongation of the MST that is described by the given distance array. The input distance \n","    array represents the distances of each node in the graph from the root of the graph (the starting point). \n","    Funciton calculates the elongation by dividing the half-length of the tree by the half-width.\n","    The half-width is calculated as the average width in every depth level, and the half-length is calculated as the\n","    average distance from the root.\n","\n","    Parameters\n","    -------\n","    :param distance_arr: list, a list that described the distance of each node from the root of the tree\n","\n","    Returns\n","    -------\n","    :param mst_elongation: float, the elongation of the MST\n","    \"\"\"\n","    graph_half_length = numpy.average(distance_arr) \n","    g_unique, counts = numpy.unique(distance_arr, return_counts=True)\n","    graph_half_width = numpy.average(counts) / 2.\n","    mst_elongation = float(graph_half_length) / float(graph_half_width) + 1 \n","\n","    return mst_elongation\n","\n","def apply_MST_and_return_MST_and_elongation(distance_matrix, return_elongation=True):\n","    \"\"\"Function converts the distance matrix into a fully-conncted graph and calculates its Minimum Spanning Tree (MST).\n","    Function has an option to return the elongation of the resulting MST. \n","\n","    Parameters\n","    -------\n","    :param distance_matrix: numpy.ndarray(), the distance matrix that will be converted into an MST.\n","    :param return_elongation: boolean (default=True), whether to return the elongation of the resulting MST.\n","\n","    Returns\n","    -------\n","    :param G: networkx.classes.graph.Graph(), the graph that represents the resulting MST.\n","    :param mst_elongation (optional): float, the elongation of the resulting MST.\n","    \"\"\"\n","    assert type(distance_matrix) == numpy.ndarray, \"distance matrix must be numpy.ndarray\"\n","    assert len(distance_matrix.shape) == 2, \"distance matrix must have 2 dimensions\"\n","    assert distance_matrix.shape[0] == distance_matrix.shape[1], \"distance matrix must be NxN matrix\"\n","    assert (~numpy.isnan(distance_matrix)).all(), \"distance matrix contains nan values\"\n","    assert (~numpy.isneginf(distance_matrix)).all(), \"distance matrix contains negative infinite values\"\n","    assert (distance_matrix.round(5) >= 0).all(), \"distance matrix contains negative values\"\n","    assert (distance_matrix.diagonal() == 0).all(), \"distance matrix must contain zeros in its diagonal\"\n","\n","    min_span_dist_mat = minimum_spanning_tree(csr_matrix(distance_matrix)).toarray()\n","    G = nx.from_scipy_sparse_matrix(minimum_spanning_tree(csr_matrix(distance_matrix)))\n","    if return_elongation:\n","        start_index = return_start_index_from_MST(G)\n","        distance_dict = nx.shortest_path_length(G, start_index)\n","        distance_arr = numpy.fromiter(distance_dict.values(), dtype=int)\n","        mst_elongation = return_MST_elongation(distance_arr)\n","        return G, mst_elongation\n","    else:\n","        return G\n","\n","\n","\n","\n","\n","\n","\n","\n","#######################################################################################################################\n","#######################################################################################################################\n","#######################################################################################################################\n","#######################################################################################################################\n","####################################################### DISTANCE MATRIX ###############################################\n","#######################################################################################################################\n","#######################################################################################################################\n","####################################################### IMPORTS #######################################################\n","#######################################################################################################################\n","\n","import numpy\n","from scipy.stats import wasserstein_distance\n","from scipy.stats import energy_distance\n","from scipy.stats import entropy\n","import multiprocessing\n","from joblib import Parallel, delayed\n","\n","#from emd import emd\n","\n","#######################################################################################################################\n","##  Euclidean Distance:                                                                                              ##\n","##  (1) Can be applied to both 1D (vectors) and 2D (images) without special treatment for the different dimensions.  ##\n","##  (2) The distance matrix is symmetric, so the calculations can be reduced by a factor of two.                     ##\n","#######################################################################################################################\n","\n","def return_L2_mat(objects_list, choice_parallelization):\n","    \"\"\"Returns the Euclidean Distance matrix for the list of objects.\n","\n","    :param objects_list: a list of objects between which the distance will be calculated. Objects are assumed \n","                         be numpy.array\n","    :param choice_parallelization: a boolean variable reprensting whether to parallelize the computation\n","    :rtype: numpy.array\n","    \"\"\"\n","    n_obj = len(objects_list)\n","    distance_matrix = numpy.zeros((n_obj, n_obj))\n","\n","    if choice_parallelization == True:\n","        master_index_list = []\n","        for i in range(n_obj):\n","            for j in range(i+1, n_obj):\n","                master_index_list.append([i,j])\n","\n","        num_cores = multiprocessing.cpu_count()\n","        results = Parallel(n_jobs=num_cores)(delayed(l2_simple)(objects_list, i) for i in master_index_list)\n","\n","        for i_pair in range(len(results)):\n","            i = master_index_list[i_pair][0]\n","            j = master_index_list[i_pair][1]\n","            distance_matrix[i, j] = results[i_pair]\n","            distance_matrix[j, i] = results[i_pair]\n","\n","    if choice_parallelization == False:\n","        for i in range(n_obj):\n","            for j in range(i+1, n_obj):\n","                obj_i = objects_list[i]\n","                obj_j = objects_list[j]\n","                l2_val = numpy.sum((obj_i - obj_j)**2)\n","                distance_matrix[i, j] = l2_val\n","                distance_matrix[j, i] = l2_val\n","\n","    return distance_matrix\n","\n","def l2_simple(objects_list, index_pair):\n","    \"\"\"Returns the Euclidean Distance between a pair of objects. Function is used during parallelization.\n","\n","    :param objects_list: a list of objects between which the distance will be calculated. Objects are assumed \n","                         be numpy.array\n","    :param index_pair: a list of two indices that correspond to the objects between which the distance is estimated\n","    :rtype: numpy.float64\n","    \"\"\"\n","    return numpy.sum((objects_list[index_pair[0]] - objects_list[index_pair[1]])**2)\n","\n","\n","#######################################################################################################################\n","##  KL Divergence:                                                                                                   ##\n","##  (1) Can be applied to both 1D (vectors) and 2D (images). For 2D images, the input must be flattened prior to     ##\n","##      application.                                                                                                 ##\n","##  (2) The distance matrix is asymmetric.                                                                           ## \n","#######################################################################################################################\n","\n","def return_kl_mat(objects_list, choice_parallelization):\n","    \"\"\"Returns the KL Divergence matrix for the list of objects.\n","\n","    :param objects_list: a list of objects between which the distance will be calculated. Objects are assumed \n","                         be numpy.array\n","    :param choice_parallelization: a boolean variable reprensting whether to parallelize the computation\n","    :rtype: numpy.array\n","    \"\"\"\n","    n_obj = len(objects_list)\n","    distance_matrix = numpy.zeros((n_obj, n_obj))\n","\n","    if choice_parallelization == True:\n","        master_index_list = []\n","        for i in range(n_obj):\n","            for j in range(n_obj):\n","                master_index_list.append([i, j])\n","\n","        num_cores = multiprocessing.cpu_count()\n","        results = Parallel(n_jobs=num_cores)(delayed(kl_simple)(objects_list, i) for i in master_index_list)\n","\n","        for i_pair in range(len(results)):\n","            i = master_index_list[i_pair][0]\n","            j = master_index_list[i_pair][1]\n","            distance_matrix[i, j] = results[i_pair]\n","\n","    if choice_parallelization == False:\n","            for i in range(n_obj):\n","                for j in range(n_obj):\n","                    obj_i = objects_list[i].flatten()\n","                    obj_j = objects_list[j].flatten()\n","                    distance_matrix[i, j] = entropy(obj_i, obj_j)\n","\n","    return distance_matrix\n","\n","def kl_simple(objects_list, index_pair):\n","    \"\"\"Returns the KL Divergence between a pair of objects. Function is used during parallelization.\n","\n","    :param objects_list: a list of objects between which the distance will be calculated. Objects are assumed \n","                         be numpy.array\n","    :param index_pair: a list of two indices that correspond to the objects between which the distance is estimated\n","    :rtype: numpy.float64\n","    \"\"\"\n","    obj_i = objects_list[index_pair[0]].flatten()\n","    obj_j = objects_list[index_pair[1]].flatten()\n","    return entropy(obj_i, obj_j)\n","\n","#######################################################################################################################\n","##  Earth Mover Distance:                                                                                            ##\n","##  (1) Can be applied to both 1D (vectors) and 2D (images). For 1D objects, there is a scipy function which is      ##\n","##      very fast. For 2D objects, we must solve a transportation problem and the computation is very long.          ##\n","##  (2) The distance matrix is symmetric, so the calculations can be reduced by a factor of two.                     ##\n","#######################################################################################################################\n","\n","def return_emd_mat_brute_force(grid, objects_list, choice_parallelization):\n","    \"\"\"Returns the Earth Mover Distance matrix for the list of objects.\n","\n","    :param grid: a numpy.array representing the grid on which the objects lie (the x-axis essentially)\n","    :param objects_list: a list of objects between which the distance will be calculated. Objects are assumed \n","                         be numpy.array\n","    :param choice_parallelization: a boolean variable reprensting whether to parallelize the computation\n","    :rtype: numpy.array\n","    \"\"\"\n","    n_obj = len(objects_list)\n","    n_pix = len(grid)\n","    distance_matrix = numpy.zeros((n_obj, n_obj))\n","\n","    if choice_parallelization == True:\n","        master_index_list = []\n","        for i in range(n_obj):\n","            for j in range(i+1, n_obj):\n","                master_index_list.append([i, j])\n","\n","        num_cores = multiprocessing.cpu_count()\n","        if len(grid.shape) == 1:\n","            results = Parallel(n_jobs=num_cores)(delayed(emd_simple_1D)(grid, objects_list, i) for i in master_index_list)\n","        if len(grid.shape) == 2:\n","            results = Parallel(n_jobs=num_cores)(delayed(emd_simple_2D)(grid, objects_list, i) for i in master_index_list)\n","\n","        for i_pair in range(len(results)):\n","            i = master_index_list[i_pair][0]\n","            j = master_index_list[i_pair][1]\n","            distance_matrix[i, j] = results[i_pair]\n","            distance_matrix[j, i] = results[i_pair]\n","\n","    if choice_parallelization == False:\n","        if len(grid.shape) == 1:\n","            for i in range(n_obj):\n","                for j in range(i+1, n_obj):\n","                    obj_i = objects_list[i]\n","                    obj_j = objects_list[j]\n","                    emd_val = wasserstein_distance(grid, grid, u_weights=obj_i, v_weights=obj_j)\n","                    distance_matrix[i, j] = emd_val\n","                    distance_matrix[j, i] = emd_val\n","\n","        if len(grid.shape) == 2:\n","            for i in range(n_obj):\n","                for j in range(i+1, n_obj):\n","                    obj_i = objects_list[i]\n","                    obj_j = objects_list[j]\n","\n","                    X = numpy.column_stack(numpy.nonzero(obj_i))\n","                    Y = numpy.column_stack(numpy.nonzero(obj_j))\n","                    X_w = obj_i[numpy.nonzero(obj_i)] \n","                    Y_w = obj_j[numpy.nonzero(obj_j)]\n","                    emd_val = emd(X, Y, X_weights=X_w, Y_weights=Y_w)\n","\n","                    distance_matrix[i, j] = emd_val\n","                    distance_matrix[j, i] = emd_val\n","\n","    return distance_matrix\n","\n","def emd_simple_1D(grid, objects_list, index_pair):\n","    \"\"\"Returns the Earth Mover Distance between a pair of objects. Function is used during parallelization.\n","\n","    :param grid: a numpy.array representing the grid on which the objects lie (the x-axis essentially)\n","    :param objects_list: a list of objects between which the distance will be calculated. Objects are assumed \n","                         be numpy.array\n","    :param index_pair: a list of two indices that correspond to the objects between which the distance is estimated\n","    :rtype: numpy.float64\n","    \"\"\"\n","    return wasserstein_distance(grid, grid, u_weights=objects_list[index_pair[0]], v_weights=objects_list[index_pair[1]])\n","\n","def emd_simple_2D(grid, objects_list, index_pair):\n","    \"\"\"Returns the Earth Mover Distance between a pair of objects. Function is used during parallelization.\n","\n","    :param grid: a numpy.array representing the grid on which the objects lie (the x-axis essentially)\n","    :param objects_list: a list of objects between which the distance will be calculated. Objects are assumed \n","                         be numpy.array\n","    :param index_pair: a list of two indices that correspond to the objects between which the distance is estimated\n","    :rtype: numpy.float64\n","    \"\"\"\n","    obj_i = objects_list[index_pair[0]]\n","    obj_j = objects_list[index_pair[1]]\n","    X = numpy.column_stack(numpy.nonzero(obj_i))\n","    Y = numpy.column_stack(numpy.nonzero(obj_j))\n","    X_w = obj_i[numpy.nonzero(obj_i)] \n","    Y_w = obj_j[numpy.nonzero(obj_j)]\n","\n","    return emd(X, Y, X_weights=X_w, Y_weights=Y_w)\n","\n","#######################################################################################################################\n","##  Energy Distance:                                                                                                 ##\n","##  (1) Can only be applied 1D objects.                                                                              ##\n","##  (2) The distance matrix is symmetric, so the calculations can be reduced by a factor of two.                     ##\n","#######################################################################################################################\n","\n","def return_energy_mat(grid, objects_list, choice_parallelization):\n","    \"\"\"Returns the Energy Distance matrix for the list of objects.\n","\n","    :param grid: a numpy.array representing the grid on which the objects lie (the x-axis essentially)\n","    :param objects_list: a list of objects between which the distance will be calculated. Objects are assumed \n","                         be numpy.array\n","    :param choice_parallelization: a boolean variable reprensting whether to parallelize the computation\n","    :rtype: numpy.array\n","    \"\"\"\n","    assert len(grid.shape) == 1, \"energy distance can only be applied on 1D objects\"\n","\n","    n_obj = len(objects_list)\n","    n_pix = len(grid)\n","    distance_matrix = numpy.zeros((n_obj, n_obj))\n","\n","    if choice_parallelization == True:\n","        master_index_list = []\n","        for i in range(n_obj):\n","            for j in range(i+1, n_obj):\n","                master_index_list.append([i, j])\n","\n","        num_cores = multiprocessing.cpu_count()\n","        results = Parallel(n_jobs=num_cores)(delayed(energy_simple_1D)(grid, objects_list, i) for i in master_index_list)\n","\n","        for i_pair in range(len(results)):\n","            i = master_index_list[i_pair][0]\n","            j = master_index_list[i_pair][1]\n","            distance_matrix[i, j] = results[i_pair]\n","            distance_matrix[j, i] = results[i_pair]\n","\n","    if choice_parallelization == False:\n","        for i in range(n_obj):\n","            for j in range(i+1, n_obj):\n","                obj_i = objects_list[i]\n","                obj_j = objects_list[j]\n","                energy_val = energy_distance(grid, grid, u_weights=obj_i, v_weights=obj_j)\n","                distance_matrix[i, j] = energy_val\n","                distance_matrix[j, i] = energy_val\n","\n","    return distance_matrix\n","\n","def energy_simple_1D(grid, objects_list, index_pair):\n","    \"\"\"Returns the Earth Mover Distance between a pair of objects. Function is used during parallelization.\n","\n","    :param grid: a numpy.array representing the grid on which the objects lie (the x-axis essentially)\n","    :param objects_list: a list of objects between which the distance will be calculated. Objects are assumed \n","                         be numpy.array\n","    :param index_pair: a list of two indices that correspond to the objects between which the distance is estimated\n","    :rtype: numpy.float64\n","    \"\"\"\n","    return energy_distance(grid, grid, u_weights=objects_list[index_pair[0]], v_weights=objects_list[index_pair[1]])\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Dayla's 2.0.ipynb","provenance":[{"file_id":"1k5CzBDYtLfCRcOiqdY0fx05lSlA7MVIW","timestamp":1645651612887},{"file_id":"1-Ts0umDyNmmUSN5ofP8BScdlYaL3kg8E","timestamp":1645572874387}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":5}
